{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "privacy_ids = [f\"PP_00{i}\" for i in range(1, 10)] + [f\"PP_0{i}\" for i in range(10, 31)]\n",
    "dignity_ids = [f\"D_00{i}\" for i in range(1, 10)] + [f\"D_0{i}\" for i in range(10, 37)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: google_flan-t5-small, Law: privacy, Action: 0\n",
      "(0.10453295313490726, 0.10394627151525697)\n",
      "Model: google_flan-t5-base, Law: privacy, Action: 0\n",
      "(0.13266249636871114, 0.1200480971612508)\n",
      "Model: google_flan-t5-large, Law: privacy, Action: 0\n",
      "(0.047463850886094554, 0.05513200947102995)\n",
      "Model: bigscience_bloomz-560m, Law: privacy, Action: 0\n",
      "(0.14782372582591505, 0.1287564527348985)\n",
      "Model: bigscience_bloomz-1b1, Law: privacy, Action: 0\n",
      "(0.08213946081165759, 0.11931422720080304)\n",
      "Model: bigscience_bloomz-1b7, Law: privacy, Action: 0\n",
      "(0.1284475528980889, 0.10414527892470413)\n",
      "Model: bigscience_bloomz-3b, Law: privacy, Action: 0\n",
      "(0.11018293663453348, 0.1084792562331948)\n",
      "Model: google_flan-t5-small, Law: dignity, Action: 0\n",
      "(0.0983472233418479, 0.07099145727806946)\n",
      "Model: google_flan-t5-base, Law: dignity, Action: 0\n",
      "(0.0755338727238371, 0.07215384427343063)\n",
      "Model: google_flan-t5-large, Law: dignity, Action: 0\n",
      "(0.055533999649503854, 0.04968522930241606)\n",
      "Model: bigscience_bloomz-560m, Law: dignity, Action: 0\n",
      "(0.10258572986117559, 0.1313792591690798)\n",
      "Model: bigscience_bloomz-1b1, Law: dignity, Action: 0\n",
      "(0.13574368609295473, 0.10439449729122333)\n",
      "Model: bigscience_bloomz-1b7, Law: dignity, Action: 0\n",
      "(0.091480570697818, 0.09827291237046551)\n",
      "Model: bigscience_bloomz-3b, Law: dignity, Action: 0\n",
      "(0.12193100894430686, 0.088979963327831)\n"
     ]
    }
   ],
   "source": [
    "def gather_scenario_ids(law : str, folder : str = \"paperlaws\") -> list[str]:\n",
    "    path = f\"data\\{folder}_scenarios\\moralchoice_{law}_ambiguity.csv\"\n",
    "    results = []\n",
    "    with open(path, 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        next(reader)\n",
    "        for row in reader:\n",
    "            results.append(row[0])\n",
    "    return results\n",
    "\n",
    "def action_likelihood(action : int, model : str, law : str) -> float:\n",
    "    # action = 0 for action1, 1 for action2\n",
    "    if law == \"dignity\" :\n",
    "        ids = dignity_ids\n",
    "    elif law == \"privacy\" :\n",
    "        ids = privacy_ids\n",
    "    else :\n",
    "        ids = gather_scenario_ids(law)\n",
    "    likelihoods_r = np.zeros(len(ids))\n",
    "    likelihoods_no_r = np.zeros(len(ids))\n",
    "    try :\n",
    "        path = f\"data/responses/new_dp\\{law}low\\{model}.csv\"\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {law}/{model}.csv\")\n",
    "        return -1\n",
    "    for scenario_id in ids:\n",
    "        actions_r = [0,0]\n",
    "        actions_no_r = [0,0]\n",
    "        with open(path, 'r') as file:\n",
    "            reader = csv.reader(file)\n",
    "            next(reader)\n",
    "            for row in reader:\n",
    "                if row[1] == scenario_id:\n",
    "                    if row[3] in ['ab_d','compare_d','repeat_d','ab_p','compare_p','repeat_p'] :\n",
    "                        if 'action1' in row : actions_r[0] += 1\n",
    "                        elif 'action2' in row : actions_r[1] += 1\n",
    "                    elif row[3] in ['ab','compare','repeat'] :\n",
    "                        if 'action1' in row : actions_no_r[0] += 1\n",
    "                        elif 'action2' in row : actions_no_r[1] += 1\n",
    "        sum_r = actions_r[0] + actions_r[1]\n",
    "        sum_no_r = actions_no_r[0] + actions_no_r[1]\n",
    "        actions_r[0] /= sum_r\n",
    "        actions_r[1] /= sum_r\n",
    "        actions_no_r[0] /= sum_no_r\n",
    "        actions_no_r[1] /= sum_no_r\n",
    "        likelihoods_r[ids.index(scenario_id)] = actions_r[action]\n",
    "        likelihoods_no_r[ids.index(scenario_id)] = actions_no_r[action]\n",
    "    return np.std(likelihoods_r), np.std(likelihoods_no_r)\n",
    "\n",
    "models = [\"google_flan-t5-small\", \"google_flan-t5-base\", \"google_flan-t5-large\", \"bigscience_bloomz-560m\", \"bigscience_bloomz-1b1\", \"bigscience_bloomz-1b7\", \"bigscience_bloomz-3b\"]\n",
    "laws = [\"kill\", \"pain\", \"disable\", \"freedom\", \"pleasure\", \"deceive\", \"cheat\", \"break_promise\", \"break_law\", \"duty\"]\n",
    "laws2 = laws + [\"privacy\",\"dignity\"]\n",
    "\n",
    "for law in [\"privacy\", \"dignity\"]:\n",
    "    for model in models:\n",
    "        print(f\"Model: {model}, Law: {law}, Action: {0}\")\n",
    "        print(action_likelihood(0, model, law))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: google_flan-t5-small, Law: privacy, Action: 0\n",
      "Error\n",
      "Model: google_flan-t5-base, Law: privacy, Action: 0\n",
      "Error\n",
      "Model: google_flan-t5-large, Law: privacy, Action: 0\n",
      "Error\n",
      "Model: bigscience_bloomz-560m, Law: privacy, Action: 0\n",
      "Error\n",
      "Model: bigscience_bloomz-1b1, Law: privacy, Action: 0\n",
      "Error\n",
      "Model: bigscience_bloomz-1b7, Law: privacy, Action: 0\n",
      "Error\n",
      "Model: bigscience_bloomz-3b, Law: privacy, Action: 0\n",
      "Error\n",
      "Model: google_flan-t5-small, Law: dignity, Action: 0\n",
      "Error\n",
      "Model: google_flan-t5-base, Law: dignity, Action: 0\n",
      "Error\n",
      "Model: google_flan-t5-large, Law: dignity, Action: 0\n",
      "Error\n",
      "Model: bigscience_bloomz-560m, Law: dignity, Action: 0\n",
      "Error\n",
      "Model: bigscience_bloomz-1b1, Law: dignity, Action: 0\n",
      "Error\n",
      "Model: bigscience_bloomz-1b7, Law: dignity, Action: 0\n",
      "Error\n",
      "Model: bigscience_bloomz-3b, Law: dignity, Action: 0\n",
      "Error\n"
     ]
    }
   ],
   "source": [
    "for law in [\"privacy\", \"dignity\"]:\n",
    "    for model in models:\n",
    "        print(f\"Model: {model}, Law: {law}, Action: {0}\")\n",
    "        try :\n",
    "            print(action_likelihood(0, model, law))\n",
    "        except :\n",
    "            print(\"Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(action_likelihood(0, law, model, law))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
